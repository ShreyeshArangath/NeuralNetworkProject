{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b4f873-50b5-4ebb-a139-271aa10082ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "# from keras.preprocessing import image\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68288b2e-6b15-4f41-83f9-7f7665d1d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.chdir ('./Project/Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de10a208-6a91-4bd4-a979-7759022f6e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shreyesh/Desktop/Spring 2022/Neural Networks/Project/Code'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a19386d-bd78-48b1-9506-c011c5591a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# Retrieve training data\n",
    "# remove subset param\n",
    "def getDataset(dataFolder, subset, imageSize = (224, 224), batchSize = 32):\n",
    "    train_ds = keras.utils.image_dataset_from_directory(\n",
    "      dataFolder,\n",
    "      seed=123,\n",
    "      image_size=imageSize,\n",
    "      batch_size=batchSize)\n",
    "    return train_ds\n",
    "\n",
    "# Tune buffer size and efficiency \n",
    "# When do we call this?\n",
    "def configurePerformance(train_ds, val_ds): \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# def buildModel(dropoutRate, numClasses, inpShape = (224, 224, 3)):\n",
    "import pickle\n",
    "\n",
    "# Create pkl file of the model after the training phase\n",
    "def dumpModel(modelName, phase): \n",
    "    # Save the trained model as a pickle string.\n",
    "    modelName = \"model_\" + modelName + \"_ \" + phase + \".pkl\"\n",
    "    pickle.dump(model, open(modelName, 'wb'))\n",
    "    \n",
    "def getDatasetsByCar(cars):\n",
    "    train_ds = None \n",
    "    val_ds = None \n",
    "    for car in cars: \n",
    "        trainingFolder = 'data/'+ car +'/train/RGB/'\n",
    "        testingFolder = 'data/'+ car + '/test_with_labels/RGB/'\n",
    "        if not train_ds and not val_ds:\n",
    "            train_ds = getDataset(trainingFolder, \"training\")\n",
    "            val_ds =  getDataset(testingFolder, \"validation\")\n",
    "        else: \n",
    "            new_train_ds =  getDataset(trainingFolder, \"training\")\n",
    "            new_val_ds =  getDataset(testingFolder, \"validation\")\n",
    "            train_ds.concatenate(new_train_ds)\n",
    "            val_ds.concatenate(new_val_ds)\n",
    "    return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ca62f41-7a7e-4976-9ebb-e6b3994b05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 7 classes.\n",
      "Found 1500 files belonging to 7 classes.\n",
      "Found 6000 files belonging to 7 classes.\n",
      "Found 1500 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "modelName = \"vgg16\"\n",
    "# Initial layer input shape\n",
    "inpShape =  (224, 224, 3)\n",
    "cars = ['x5', 'model3']\n",
    "train_ds, val_ds = getDatasetsByCar(cars)\n",
    "\n",
    "# trainingFolder = 'data/x5/train/RGB/'\n",
    "# testingFolder = 'data/x5/test_with_labels/RGB/'\n",
    "# # don't need to pass subset string - datasets already split\n",
    "# train_ds = getDataset(trainingFolder, \"training\")\n",
    "# val_ds =  getDataset(testingFolder, \"validation\")\n",
    "\n",
    "train_ds, val_ds = configurePerformance(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8792a52b-b5ca-467a-a217-1cfbcd475477",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoutRate = 0.2\n",
    "numClasses = 7 \n",
    "inp = layers.Input(shape=inpShape)\n",
    "baseModel = VGG16(weights=\"imagenet\",\n",
    "                   include_top = False) \n",
    "baseModel.trainable = False \n",
    "x = baseModel(inp, training=False)\n",
    "x =  layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "x = layers.Dropout(dropoutRate, noise_shape=None, seed=None)(x)\n",
    "out = layers.Dense(numClasses,activation=\"softmax\", name = \"pred\")(x)\n",
    "model = keras.Model(inp, out, name=\"FeatureExtraction-B0\")\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "          # metrics=['accuracy']\n",
    "          metrics=['accuracy',\n",
    "              recall_m,\n",
    "              precision_m,\n",
    "              f1_m\n",
    "              ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e9f4b-573d-4dc7-b6e0-7468daead50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 12:21:39.052573: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-15 12:21:39.053135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.8400 - accuracy: 0.7997 - recall_m: 1.2673 - precision_m: 0.8042 - f1_m: 0.9778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 12:23:31.879010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 139s 681ms/step - loss: 0.8400 - accuracy: 0.7997 - recall_m: 1.2673 - precision_m: 0.8042 - f1_m: 0.9778 - val_loss: 1.5861 - val_accuracy: 0.6553 - val_recall_m: 1.5036 - val_precision_m: 0.9691 - val_f1_m: 1.1726\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 138s 736ms/step - loss: 0.3315 - accuracy: 0.9020 - recall_m: 1.1355 - precision_m: 0.6950 - f1_m: 0.8572 - val_loss: 1.6377 - val_accuracy: 0.6507 - val_recall_m: 1.3456 - val_precision_m: 0.8379 - val_f1_m: 1.0276\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 141s 747ms/step - loss: 0.3002 - accuracy: 0.9162 - recall_m: 1.1120 - precision_m: 0.6753 - f1_m: 0.8354 - val_loss: 2.7379 - val_accuracy: 0.6387 - val_recall_m: 1.2760 - val_precision_m: 0.7755 - val_f1_m: 0.9603\n",
      "Epoch 4/5\n",
      " 40/188 [=====>........................] - ETA: 1:24 - loss: 0.2059 - accuracy: 0.9391 - recall_m: 1.0978 - precision_m: 0.6560 - f1_m: 0.8155"
     ]
    }
   ],
   "source": [
    "# Feature extraction without the top layers \n",
    "hist_results = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92b00c-3c3a-4822-8886-bf0215611cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpModel(modelName, \"phase1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

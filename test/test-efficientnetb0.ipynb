{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5ac6be5e-88ca-4678-864f-dfa9dfc0b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras, sparse \n",
    "from keras import layers, applications\n",
    "# from keras.preprocessing import image\n",
    "from keras.applications.efficientnet import EfficientNetB0, EfficientNetB5, EfficientNetB7\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.applications.densenet import DenseNet121\n",
    "# from keras.applications import EfficientNetB0\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Data preprocessing \n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b6e994d5-6388-410d-b7b8-71deb9436759",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subset IN (TRAINING, VALIDATION)\n",
    "\"\"\"\n",
    "      validation_split=0.05,\n",
    "      subset= subset,\n",
    "\"\"\"\n",
    "def getDataset(dataFolder, subset, imageSize = (224, 224), batchSize = 32):\n",
    "    train_ds = keras.utils.image_dataset_from_directory(\n",
    "      dataFolder,\n",
    "      seed=123,\n",
    "      image_size=imageSize,\n",
    "      batch_size=batchSize)\n",
    "    return train_ds\n",
    "\n",
    "\n",
    "def configurePerformance(train_ds, val_ds): \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "def buildModel(dropoutRate, numClasses):\n",
    "    inp = layers.Input(shape=inp_shape)\n",
    "    baseModel = EfficientNetB0(weights=\"imagenet\",\n",
    "                       include_top = False) \n",
    "    baseModel.trainable = False \n",
    "    x = baseModel(inp, training=False)\n",
    "    x =  layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "    x = layers.Dropout(dropoutRate, noise_shape=None, seed=None)(x)\n",
    "    out = layers.Dense(numClasses,activation=\"softmax\", name = \"pred\")(x)\n",
    "    model = keras.Model(inp, out, name=\"B0\")\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a1d06caf-e4d9-4f7a-bed6-84686a8c9e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 7 classes.\n",
      "Found 1500 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "trainingFolder = 'data/x5_RGB/train/RGB/'\n",
    "testingFolder = 'data/x5_RGB/test_with_labels/RGB/'\n",
    "train_ds = getDataset(trainingFolder, \"training\")\n",
    "val_ds =  getDataset(testingFolder, \"validation\")\n",
    "model = buildModel(0.2, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "69715cb6-c486-42ab-b827-81f51f919ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:27:18.851054: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.7705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:28:02.496578: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 62s 307ms/step - loss: 0.7443 - accuracy: 0.7705 - val_loss: 0.9447 - val_accuracy: 0.6440\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 53s 278ms/step - loss: 0.3746 - accuracy: 0.8872 - val_loss: 0.8981 - val_accuracy: 0.6633\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 52s 276ms/step - loss: 0.2991 - accuracy: 0.9062 - val_loss: 0.8813 - val_accuracy: 0.6693\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 52s 274ms/step - loss: 0.2605 - accuracy: 0.9183 - val_loss: 0.8981 - val_accuracy: 0.6707\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 53s 283ms/step - loss: 0.2338 - accuracy: 0.9267 - val_loss: 0.8884 - val_accuracy: 0.6867\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 53s 282ms/step - loss: 0.2151 - accuracy: 0.9313 - val_loss: 0.8949 - val_accuracy: 0.6867\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 53s 283ms/step - loss: 0.2015 - accuracy: 0.9367 - val_loss: 0.9045 - val_accuracy: 0.6887\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 51s 271ms/step - loss: 0.1895 - accuracy: 0.9383 - val_loss: 0.9097 - val_accuracy: 0.6967\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 64s 337ms/step - loss: 0.1825 - accuracy: 0.9438 - val_loss: 0.9290 - val_accuracy: 0.6973\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 77s 405ms/step - loss: 0.1714 - accuracy: 0.9470 - val_loss: 0.9283 - val_accuracy: 0.7053\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d898caa7-24ae-42d6-883c-3bc9ab3dca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://cb986ee5-de15-4079-9011-3659a85c3883/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model as a pickle string.\n",
    "pickle.dump(model, open('model.pkl', 'wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aa1e5a1b-28d9-4cad-be7f-73cc7943c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-05 17:47:34.977248: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 14s 246ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(val_ds, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a622d974-c169-49c5-8d9e-b67db1ae3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageRepresentation():\n",
    "    import random\n",
    "    pred_labels = tf.argmax(preds, axis=1)\n",
    "    test_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "    test_image_batches = []\n",
    "    for images, labels in val_ds.take(-1):\n",
    "        test_image_batches.append(images.numpy())\n",
    "\n",
    "    test_images = [item for sublist in test_image_batches for item in sublist]\n",
    "    plt.figure(figsize = (20,20))\n",
    "    for i in range(9):\n",
    "        random_int_index = random.choice(range(len(test_images)))\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(test_images[random_int_index]/255.)\n",
    "        if test_labels[random_int_index] == pred_labels[random_int_index]:\n",
    "            color = \"g\"\n",
    "        else:\n",
    "            color = \"r\"\n",
    "        plt.title(\"True Label: \" + class_names[test_labels[random_int_index]] + \" || \" + \"Predicted Label: \" +\n",
    "                  class_names[pred_labels[random_int_index]] + \"\\n\" + \n",
    "                  str(np.asarray(tf.reduce_max(preds, axis = 1))[random_int_index]), c=color)\n",
    "        plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dfae637e-8181-4f4a-8845-ff71618dad1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 12s 228ms/step - loss: 0.9283 - accuracy: 0.7053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9282761216163635, 0.7053333520889282]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b870cc2-2472-4316-a976-7d072dc6af9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6b4f873-50b5-4ebb-a139-271aa10082ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "# from keras.preprocessing import image\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68288b2e-6b15-4f41-83f9-7f7665d1d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.chdir ('./Project/Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de10a208-6a91-4bd4-a979-7759022f6e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shreyesh/Desktop/Spring 2022/Neural Networks/Project/Code'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a19386d-bd78-48b1-9506-c011c5591a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# Retrieve training data\n",
    "# remove subset param\n",
    "def getDataset(dataFolder, subset, imageSize = (224, 224), batchSize = 32):\n",
    "    train_ds = keras.utils.image_dataset_from_directory(\n",
    "      dataFolder,\n",
    "      seed=123,\n",
    "      image_size=imageSize,\n",
    "      batch_size=batchSize)\n",
    "    return train_ds\n",
    "\n",
    "# Tune buffer size and efficiency \n",
    "# When do we call this?\n",
    "def configurePerformance(train_ds, val_ds): \n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# def buildModel(dropoutRate, numClasses, inpShape = (224, 224, 3)):\n",
    "import pickle\n",
    "\n",
    "# Create pkl file of the model after the training phase\n",
    "def dumpModel(modelName, phase): \n",
    "    # Save the trained model as a pickle string.\n",
    "    modelName = \"model_\" + modelName + \"_ \" + phase + \".pkl\"\n",
    "    pickle.dump(model, open(modelName, 'wb'))\n",
    "    \n",
    "def getDatasetsByCar(cars,  imageSize = (224, 224), batchSize = 32):\n",
    "    train_ds = None \n",
    "    val_ds = None \n",
    "    for car in cars: \n",
    "        trainingFolder = 'data/'+ car +'/train/RGB/'\n",
    "        testingFolder = 'data/'+ car + '/test_with_labels/RGB/'\n",
    "        if not train_ds and not val_ds:\n",
    "            train_ds = getDataset(trainingFolder, \"training\")\n",
    "            val_ds =  getDataset(testingFolder, \"validation\")\n",
    "        else: \n",
    "            new_train_ds =  getDataset(trainingFolder, \"training\")\n",
    "            new_val_ds =  getDataset(testingFolder, \"validation\")\n",
    "            train_ds.concatenate(new_train_ds)\n",
    "            val_ds.concatenate(new_val_ds)\n",
    "    return train_ds, val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ca62f41-7a7e-4976-9ebb-e6b3994b05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 7 classes.\n",
      "Found 1500 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "modelName = \"vgg16\"\n",
    "# Initial layer input shape\n",
    "inpShape =  (224, 224, 3)\n",
    "cars = ['x5']\n",
    "train_ds, val_ds = getDatasetsByCar(cars, batchSize=64)\n",
    "\n",
    "# trainingFolder = 'data/x5/train/RGB/'\n",
    "# testingFolder = 'data/x5/test_with_labels/RGB/'\n",
    "# # don't need to pass subset string - datasets already split\n",
    "# train_ds = getDataset(trainingFolder, \"training\")\n",
    "# val_ds =  getDataset(testingFolder, \"validation\")\n",
    "\n",
    "train_ds, val_ds = configurePerformance(train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8792a52b-b5ca-467a-a217-1cfbcd475477",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoutRate = 0.2\n",
    "numClasses = 7 \n",
    "inp = layers.Input(shape=inpShape)\n",
    "baseModel = VGG16(weights=\"imagenet\",\n",
    "                   include_top = False) \n",
    "baseModel.trainable = False \n",
    "x = baseModel(inp, training=False)\n",
    "x =  layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "x = layers.Dropout(dropoutRate, noise_shape=None, seed=None)(x)\n",
    "out = layers.Dense(numClasses,activation=\"softmax\", name = \"pred\")(x)\n",
    "model = keras.Model(inp, out, name=\"FeatureExtraction-B0\")\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "          loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "          # metrics=['accuracy']\n",
    "          metrics=['accuracy',\n",
    "              recall_m,\n",
    "              precision_m,\n",
    "              f1_m\n",
    "              ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a2e9f4b-573d-4dc7-b6e0-7468daead50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 13:33:21.972255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 0.9843 - accuracy: 0.7867 - recall_m: 1.2529 - precision_m: 0.7917 - f1_m: 0.9640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 13:35:17.610104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 142s 721ms/step - loss: 0.9843 - accuracy: 0.7867 - recall_m: 1.2529 - precision_m: 0.7917 - f1_m: 0.9640 - val_loss: 1.9540 - val_accuracy: 0.5867 - val_recall_m: 1.3401 - val_precision_m: 0.8442 - val_f1_m: 1.0312\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 141s 749ms/step - loss: 0.3953 - accuracy: 0.8910 - recall_m: 1.1412 - precision_m: 0.6986 - f1_m: 0.8615 - val_loss: 2.0327 - val_accuracy: 0.6780 - val_recall_m: 1.4020 - val_precision_m: 0.8820 - val_f1_m: 1.0770\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 145s 773ms/step - loss: 0.2675 - accuracy: 0.9228 - recall_m: 1.1089 - precision_m: 0.6738 - f1_m: 0.8335 - val_loss: 2.0718 - val_accuracy: 0.6640 - val_recall_m: 1.2825 - val_precision_m: 0.7917 - val_f1_m: 0.9739\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 138s 733ms/step - loss: 0.2591 - accuracy: 0.9228 - recall_m: 1.0938 - precision_m: 0.6634 - f1_m: 0.8212 - val_loss: 2.0915 - val_accuracy: 0.6940 - val_recall_m: 1.3272 - val_precision_m: 0.8124 - val_f1_m: 1.0031\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 139s 739ms/step - loss: 0.3117 - accuracy: 0.9198 - recall_m: 1.0868 - precision_m: 0.6560 - f1_m: 0.8135 - val_loss: 2.0597 - val_accuracy: 0.6747 - val_recall_m: 1.3191 - val_precision_m: 0.8051 - val_f1_m: 0.9953\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction without the top layers \n",
    "hist_results = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1e92b00c-3c3a-4822-8886-bf0215611cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://04f3cfc1-92dd-4a97-970b-be54f7a744f6/assets\n"
     ]
    }
   ],
   "source": [
    "dumpModel(modelName, \"phase1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7485daf-d0b3-42b4-befc-cac1115d29aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 13:46:02.158223: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - ETA: 0s - loss: 1.1336 - accuracy: 0.6290 - recall_m: 1.9905 - precision_m: 13085107.0000 - f1_m: 2.0866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 13:53:09.289012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 454s 2s/step - loss: 1.1336 - accuracy: 0.6290 - recall_m: 1.9905 - precision_m: 13085107.0000 - f1_m: 2.0866 - val_loss: 1.7893 - val_accuracy: 0.5780 - val_recall_m: 1.9610 - val_precision_m: 1.6145 - val_f1_m: 1.7512\n",
      "Epoch 6/9\n",
      "188/188 [==============================] - 432s 2s/step - loss: 0.3450 - accuracy: 0.8905 - recall_m: 1.3609 - precision_m: 0.9113 - f1_m: 1.0808 - val_loss: 2.5263 - val_accuracy: 0.6853 - val_recall_m: 1.5466 - val_precision_m: 1.0719 - val_f1_m: 1.2572\n",
      "Epoch 7/9\n",
      "188/188 [==============================] - 426s 2s/step - loss: 0.1804 - accuracy: 0.9452 - recall_m: 1.2253 - precision_m: 0.7697 - f1_m: 0.9396 - val_loss: 2.5347 - val_accuracy: 0.6913 - val_recall_m: 1.3138 - val_precision_m: 0.8243 - val_f1_m: 1.0080\n",
      "Epoch 8/9\n",
      "188/188 [==============================] - 431s 2s/step - loss: 0.0522 - accuracy: 0.9837 - recall_m: 1.0481 - precision_m: 0.6318 - f1_m: 0.7839 - val_loss: 3.3341 - val_accuracy: 0.6927 - val_recall_m: 1.3200 - val_precision_m: 0.8312 - val_f1_m: 1.0142\n",
      "Epoch 9/9\n",
      "188/188 [==============================] - 430s 2s/step - loss: 0.0363 - accuracy: 0.9883 - recall_m: 1.0376 - precision_m: 0.6262 - f1_m: 0.7766 - val_loss: 3.9797 - val_accuracy: 0.6760 - val_recall_m: 1.2051 - val_precision_m: 0.7282 - val_f1_m: 0.9037\n",
      "INFO:tensorflow:Assets written to: ram://b332995d-9115-48f3-920f-7ed5c088d93a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 14:22:21.817584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 26s 554ms/step\n",
      "47/47 [==============================] - 25s 528ms/step - loss: 3.9797 - accuracy: 0.6760 - recall_m: 1.2051 - precision_m: 0.7282 - f1_m: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.9796597957611084,\n",
       " 0.6759999990463257,\n",
       " 1.2051112651824951,\n",
       " 0.7282177805900574,\n",
       " 0.9036774635314941]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine tuning the Feature Extraction Model \n",
    "baseModel.trainable = True\n",
    "for layer in model.layers[1].layers:\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "        \n",
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy',\n",
    "              recall_m,\n",
    "              precision_m,\n",
    "              f1_m\n",
    "              ]\n",
    "              )\n",
    "\n",
    "# Train it again \n",
    "hist_results_tuned = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=9,\n",
    "  #steps_per_epoch=len(train_ds)?\n",
    "  initial_epoch=hist_results.epoch[-1]\n",
    ")\n",
    "\n",
    "dumpModel(modelName, \"phase2\")\n",
    "\n",
    "preds = model.predict(val_ds, verbose = 1)\n",
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f2fc318-3fc4-47e4-8f4d-3da9740ebb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3608278e-01, 1.8160450e-04, 2.1566679e-05, ..., 7.5970030e-01,\n",
       "        2.3007477e-03, 3.7106854e-04],\n",
       "       [9.8948485e-01, 4.6903307e-07, 4.2847299e-09, ..., 1.0490552e-02,\n",
       "        2.2224824e-05, 5.0511570e-08],\n",
       "       [1.0000000e+00, 3.4304973e-30, 1.2041805e-37, ..., 1.9341984e-19,\n",
       "        7.9030959e-27, 3.3785575e-38],\n",
       "       ...,\n",
       "       [1.3920881e-01, 3.1936724e-02, 9.1634942e-03, ..., 9.2083327e-02,\n",
       "        4.1591633e-02, 2.1902801e-02],\n",
       "       [2.0419422e-05, 8.5727197e-06, 8.5373646e-09, ..., 9.8762089e-01,\n",
       "        6.0068138e-05, 5.4565931e-05],\n",
       "       [2.5823074e-05, 1.8547093e-05, 4.9890145e-06, ..., 7.7274890e-08,\n",
       "        1.0420250e-06, 1.7978804e-05]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37878e-3b09-4c7d-bee6-0698aae4bf47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

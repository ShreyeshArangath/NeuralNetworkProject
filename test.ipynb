{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88318573-1568-4211-b219-4e0c521d447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras import layers, applications\n",
    "# from keras.preprocessing import image\n",
    "from keras.applications.efficientnet import EfficientNetB0, EfficientNetB5, EfficientNetB7\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.applications.densenet import DenseNet121\n",
    "# from keras.applications import EfficientNetB0\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "import pandas as pd \n",
    "\n",
    "# Data preprocessing \n",
    "from keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32373ff-c1fa-46c0-9858-ae6ec4bf20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the images from the folder \n",
    "dataFolder = os.path.dirname('data/x5_RGB/train/RGB/')\n",
    "imagePaths = []\n",
    "pil = []\n",
    "classLabels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1549bd9-73c6-46ea-8a48-821436313056",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "isIgnoredFile = lambda x: x[0] == \".\"\n",
    "\n",
    "for case in os.listdir(dataFolder):\n",
    "    # print(case)\n",
    "    if isIgnoredFile(case):\n",
    "        continue\n",
    "\n",
    "    f = os.path.join(dataFolder, case)\n",
    "    for image in os.listdir(f):\n",
    "        if isIgnoredFile(image):\n",
    "            continue\n",
    "        label = f[-1]\n",
    "        classLabels.append(label)\n",
    "        imagePath = os.path.join(dataFolder, case, image)\n",
    "        imagePaths.append(imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b54f5f6-89a6-47d9-ab88-3d4b8798e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=zip(classLabels, imagePaths), columns=[\"Labels\", \"Images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b7fb567-4823-4ae3-8989-40067ad029d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels in the dataset are:  {'3', '5', '4', '2', '6', '1', '0'}\n"
     ]
    }
   ],
   "source": [
    "print(\"The labels in the dataset are: \", set(df['Labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f3b455-9b8b-4056-b060-f934c265be18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_SIZE = 224 \n",
    "images = []\n",
    "for imagePath in imagePaths:\n",
    "    img = cv2.imread(imagePath)\n",
    "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))   \n",
    "    images.append(img)\n",
    "\n",
    "# Convert the images to an np array \n",
    "images = np.array(images)\n",
    "images = images.astype('float32')/255.0 #Normalize \n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75604e49-0674-4213-8b9d-b74dbb3f4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "y =df['Labels'].values\n",
    "yLabelEncoder = LabelEncoder ()\n",
    "y = yLabelEncoder.fit_transform (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b0d6841-107a-4790-87af-6ed0260c615f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (2, 0)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 0)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t1.0\n",
      "  (12, 0)\t1.0\n",
      "  (13, 0)\t1.0\n",
      "  (14, 0)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (16, 0)\t1.0\n",
      "  (17, 0)\t1.0\n",
      "  (18, 0)\t1.0\n",
      "  (19, 0)\t1.0\n",
      "  (20, 0)\t1.0\n",
      "  (21, 0)\t1.0\n",
      "  (22, 0)\t1.0\n",
      "  (23, 0)\t1.0\n",
      "  (24, 0)\t1.0\n",
      "  :\t:\n",
      "  (5940, 5)\t1.0\n",
      "  (5941, 5)\t1.0\n",
      "  (5942, 5)\t1.0\n",
      "  (5943, 5)\t1.0\n",
      "  (5944, 5)\t1.0\n",
      "  (5945, 5)\t1.0\n",
      "  (5946, 5)\t1.0\n",
      "  (5947, 5)\t1.0\n",
      "  (5948, 5)\t1.0\n",
      "  (5949, 5)\t1.0\n",
      "  (5950, 5)\t1.0\n",
      "  (5951, 5)\t1.0\n",
      "  (5952, 5)\t1.0\n",
      "  (5953, 5)\t1.0\n",
      "  (5954, 5)\t1.0\n",
      "  (5955, 5)\t1.0\n",
      "  (5956, 5)\t1.0\n",
      "  (5957, 5)\t1.0\n",
      "  (5958, 5)\t1.0\n",
      "  (5959, 5)\t1.0\n",
      "  (5960, 5)\t1.0\n",
      "  (5961, 5)\t1.0\n",
      "  (5962, 5)\t1.0\n",
      "  (5963, 5)\t1.0\n",
      "  (5964, 5)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "y=y.reshape(-1,1)\n",
    "\n",
    "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "Y = ct.fit_transform(y) #.toarray()\n",
    "print(Y[:5])\n",
    "print(Y[35:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a765c9f-7912-4561-a4df-aa7bda777024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5700, 224, 224, 3)\n",
      "(5700, 7)\n",
      "(300, 224, 224, 3)\n",
      "(300, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shufflt the data around for better training \n",
    "images, Y = shuffle(images, Y, random_state=32)\n",
    "\n",
    "TEST_SIZE = 0.05\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(images, Y, test_size=0.05, random_state=21)\n",
    "\n",
    "# Verify the shapes of the training and testing data \n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)\n",
    "print(xTest.shape)\n",
    "print(yTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df698e93-d710-47d5-94f3-78260854ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the NN \n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec70ae47-11b3-4f3f-917c-d816391df7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 14:20:12.584227: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-28 14:20:12.585553: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, None, None, 1280).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"normalization\" (type Normalization).\n\nDimensions must be equal, but are 1280 and 3 for '{{node efficientnetb0/normalization/sub}} = Sub[T=DT_FLOAT](efficientnetb0/rescaling/add, efficientnetb0/normalization/sub/y)' with input shapes: [?,?,?,1280], [1,1,1,3].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, None, None, 1280), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(b0)\n\u001b[1;32m      7\u001b[0m denseb0b5 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m456\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39madd(denseb0b5)\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd(b5)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2013\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   2010\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   2011\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2012\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 2013\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   2015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"normalization\" (type Normalization).\n\nDimensions must be equal, but are 1280 and 3 for '{{node efficientnetb0/normalization/sub}} = Sub[T=DT_FLOAT](efficientnetb0/rescaling/add, efficientnetb0/normalization/sub/y)' with input shapes: [?,?,?,1280], [1,1,1,3].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, None, None, 1280), dtype=float32)"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x = inputs \n",
    "model = Sequential()\n",
    "b0 = EfficientNetB0(weights=\"imagenet\", include_top=False)\n",
    "b5 = EfficientNetB5(weights=\"imagenet\", include_top=False)  \n",
    "model.add(b0)\n",
    "denseb0b5 = layers.Dense(456)\n",
    "model.add(b0)\n",
    "model.add(denseb0b5)\n",
    "model.add(b5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae594a4f-502a-4619-97b3-382b3263193f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
